{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import requests\n",
    "from lonboard import Map, PolygonLayer\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from matplotlib import colormaps\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population data\n",
    "\n",
    "Using [kontur population data](https://data.humdata.org/dataset/kontur-population-dataset-3km).\n",
    "\n",
    "The full 3km dataset is ~2 million polygons. Unfortunately my machine can only handle ~1-1.5 million so we'll subset to Europe and North/South America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = gpd.read_file(\n",
    "    \"https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/World_Continents/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\",\n",
    "    use_arrow=True,\n",
    ")\n",
    "\n",
    "poi = [\"Europe\", \"North America\", \"South America\", \"Africa\"]\n",
    "\n",
    "bbox = tuple(continents[continents.CONTINENT.isin(poi)].to_crs(3857).total_bounds)\n",
    "\n",
    "poly_mask = (\n",
    "    continents[continents.CONTINENT.isin(poi)]\n",
    "    .to_crs(3857)\n",
    "    .buffer(10000)\n",
    "    .to_crs(4326)\n",
    "    .union_all()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read 3km grid data from URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://geodata-eu-central-1-kontur-public.s3.eu-central-1.amazonaws.com/kontur_datasets/kontur_population_20231101_r6.gpkg.gz\"\n",
    "\n",
    "with requests.get(url, stream=True, timeout=30) as res:\n",
    "    pop_data = gzip.decompress(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data to `GeodataFrame` - ~2million polygons.\n",
    "\n",
    "*note*: assumes the default I/O engine is `pyogrio` per [GeoPandas >=1.*](https://github.com/geopandas/geopandas/releases/tag/v1.0.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanpinder/.pyenv/versions/3.10.13/lib/python3.10/contextlib.py:135: RuntimeWarning: File /vsimem/3e2836270c3f487b99df631fcaadcfde has GPKG application_id, but non conformant file extension\n",
      "  return next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2016971"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_gdf = gpd.read_file(\n",
    "    pop_data,\n",
    "    use_arrow=True,\n",
    ").to_crs(4326)\n",
    "\n",
    "len(pop_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatially filter to relevant area - ~1.28 million polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1283241"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_gdf = pop_gdf.iloc[\n",
    "    pop_gdf.sindex.query(\n",
    "        poly_mask,\n",
    "        predicate=\"intersects\",\n",
    "    )\n",
    "]\n",
    "\n",
    "len(pop_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = pop_gdf[\"population\"].to_numpy()\n",
    "heights = np.nan_to_num(heights, nan=1)\n",
    "\n",
    "normalizer = LogNorm(1, heights.max(), clip=True)\n",
    "normalized_heights = normalizer(heights)\n",
    "\n",
    "colors = apply_continuous_cmap(normalized_heights, colormaps[\"plasma\"])\n",
    "\n",
    "pop_layer = PolygonLayer.from_geopandas(\n",
    "    gdf=pop_gdf[[\"population\", \"geometry\"]],\n",
    "    extruded=True,\n",
    "    get_elevation=heights,\n",
    "    get_fill_color=colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e508aee94b3476b9f6a0eb2c3531985",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(layers=[PolygonLayer(extruded=True, get_elevation=<pyarrow.lib.FloatArray object at 0x3d8ac4100>\n",
       "[\n",
       "  5270,â€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_state = {\n",
    "    \"longitude\": -5,\n",
    "    \"latitude\": 30,\n",
    "    \"zoom\": 2,\n",
    "    \"pitch\": 45,\n",
    "    \"bearing\": 0,\n",
    "}\n",
    "\n",
    "map_layout = widgets.Layout(height=\"1200px\")\n",
    "\n",
    "m = Map(pop_layer, view_state=view_state, layout=map_layout)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.to_html(\"examples/population.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lonboard-examples-upE50-eN-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
